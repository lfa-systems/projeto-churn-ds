# üìä Previs√£o de Churn - Projeto Churn Insight

Este projeto utiliza t√©cnicas de **Machine Learning** para identificar clientes com alta probabilidade de cancelar servi√ßos (Churn). O modelo foi treinado com base de dados no dataset *Telco Customer Churn* e disponibilizado atrav√©s de uma API.

## üìÇ Estrutura do Reposit√≥rio

* **`./Projeto/`**: Diret√≥rio principal.
    * **`churn-api-ds/`**: Cont√©m o c√≥digo-fonte da API, scripts de compila√ß√£o e execut√°veis.
    * **`Dados/`**: Base de dados original em CSV utilizada para o treinamento.
    * **`Hackathon_ONE_8.ipynb`**: Notebook Jupyter com a an√°lise explorat√≥ria, tratamento de dados e treinamento do modelo.

## üß† O Modelo
O modelo utiliza **Regress√£o Log√≠stica** com ajuste de `class_weight='balanced'` para lidar com o desequil√≠brio das classes. 

### M√©tricas Alcan√ßadas:
* **Recall (Classe 1):** ~80% (Foco em n√£o deixar nenhum cliente em risco escapar).
* **Acur√°cia:** Equilibrada para evitar falsos negativos.

## üìà Performance do Modelo
O modelo foi avaliado utilizando um conjunto de teste independente (20% dos dados). Abaixo est√£o as m√©tricas detalhadas:
---
=== Relat√≥rio de Performance ===

      Classe  precision    recall  f1-score   support

           0       0.90      0.71      0.80      1033
           1       0.50      0.79      0.61       374

    accuracy                           0.73      1407

---
# Entedendo o rela√≥tio
### 1. O Ponto de Partida: O "Support"
O relat√≥rio diz que foram testados 1.407 clientes:

* **Classe 0 (Ficaram):** 1.033 clientes.
* **Classe 1 (Sa√≠ram):**    374 clientes.

### 2. Calculando os Acertos (Verdadeiros Positivos e Negativos)
Para descobrir os acertos, multiplicamos o Recall pelo Support:

* **Acerto de quem FICA (Verdadeiro Negativo):** O Recall da classe 0 √© 0.71. logo $1.033 \times 0.71 = \mathbf{733}$ clientes.
* **Acerto de quem SAI (Verdadeiro Positivo):** O Recall da classe 1 √© 0.79. logo $374 \times 0.79 = \mathbf{296}$ clientes (arredondado).

### 3. Calculando os Erros (Falsos Positivos e Negativos)

Agora, basta subtrair os acertos do total de cada grupo:

* **Falso Alarme (Falso Positivo):** Eram 1.033 que ficaram, mas o modelo acertou 733.$1.033 - 733 = \mathbf{300}$ clientes (O modelo disse que iam sair, mas eles ficaram).
* **Falha de Detec√ß√£o (Falso Negativo):** Eram 374 que sa√≠ram, mas o modelo acertou 296.$374 - 296 = \mathbf{78}$ clientes (Eles sa√≠ram e o modelo n√£o percebeu).
---
üí° Por que esses n√∫meros importam para o Neg√≥cio?
Ao configurar o modelo, priorizamos o Recall em detrimento da Precis√£o na classe 1.

O racioc√≠nio √© simples:

Custo do Falso Positivo (Baixa Precis√£o na classe 1): O custo de oferecer um desconto ou ligar para um cliente que n√£o ia sair √© baixo.

Custo do Falso Negativo (Baixo Recall na classe 1): O custo de perder um cliente para a concorr√™ncia porque o modelo n√£o o detectou √© alt√≠ssimo (perda de receita recorrente).

Com um Recall de 79%, o "Robozinho Detetive" atua como uma rede de prote√ß√£o eficaz para o faturamento da empresa.
---

## üèÜ O qu√£o bom √© o nosso "Robozinho Detetive"?
Traduzindo os n√∫meros para o dia a dia da empresa, veja o que o modelo entrega:

üéØ Olhar de √Åguia para o Risco (Recall: 79%): De cada 10 clientes que est√£o pensando em nos deixar, o modelo consegue "pescar" 8 deles antes de eles irem embora. Isso d√° tempo para o time de marketing agir e salvar o contrato!

‚úÖ Certeza de quem est√° satisfeito (Precis√£o: 90%): Quando o rob√¥ diz "esse cliente est√° feliz e vai ficar", ele acerta 9 em cada 10 vezes. Isso evita gastos desnecess√°rios com promo√ß√µes para quem j√° √© fiel.

‚öñÔ∏è Equil√≠brio Realista (Acur√°cia: 73%): O modelo n√£o tenta "adivinhar" por sorte. Ele mant√©m um p√© no ch√£o, focando no que realmente importa: n√£o deixar o lucro sair pela porta.

üöÄ Por que isso √© dinheiro no bolso?
Em vez de disparar descontos para todo mundo, agora a empresa pode ser cir√∫rgica:

Economia: N√£o damos b√¥nus para quem j√° ia ficar (90% de acerto aqui!).

Reten√ß√£o: Agimos nos 80% de clientes em risco que antes eram "invis√≠veis".

Estrat√©gia: O modelo foca no preju√≠zo que d√≥i mais: o cliente que vai embora sem a gente perceber.

## üõ†Ô∏è Como usar
Para entender o treinamento, abra o arquivo `.ipynb`. Para rodar o sistema de predi√ß√£o em tempo real, acesse a pasta `churn-api-ds`.


----

## üõ†Ô∏è Como Executar

### 1. An√°lise e Treinamento

   Se deseja ver como o "c√©rebro" foi treinado:

   1. Abra o arquivo `Hackathon_ONE_8.ipynb` no Google Colab ou Jupyter Notebook.
   2. Certifique-se de que o arquivo `WA_Fn-UseC_-Telco-Customer-Churn.csv` est√° na pasta /Dados.
   3. Execute as c√©lulas para gerar os arquivos `.pkl` (modelo e scaler).
   
### 2. Rodando a API (Servidor de Predi√ß√£o)

    Se deseja colocar o modelo para trabalhar:
    
    Bash#
    
    # Entre na pasta da API
    cd Projeto/churn-api-ds

    # Execute o servidor
    python run_server.py

Acesse http://localhost:8000 para abrir a interface de cadastro e testar novos clientes.

üìä Matriz de Resultados (O que os n√∫meros dizem)Para quem prefere ver o "placar" do jogo, aqui est√° como o modelo se comportou com os 1.407 clientes de teste:Realidade \ Previs√£oPreviu: FICAPreviu: SAICliente FICOU733 (Acerto)300 (Alarme Falso)Cliente SAIU78 (N√£o detectado)296 (Acerto Cr√≠tico)Nota: Perceba que o modelo prefere dar um "Alarme Falso" (300) do que deixar um cliente sair sem aviso (apenas 78). Essa √© a nossa estrat√©gia de Recall de 79% em a√ß√£o!üèóÔ∏è Dica para o diret√≥rio churn-api-dsComo voc√™ tem uma pasta build e arquivos .spec, o seu README de l√° j√° menciona o execut√°vel. Isso √© √≥timo! Mostra que o projeto est√° pronto para sair da m√°quina do desenvolvedor e ir para um servidor real.O seu projeto est√° complet√≠ssimo agora! Ele tem:Dados reais filtrados.Modelo inteligente com foco em neg√≥cio (Recall).API robusta com tratamentos de erros (try/except).Documenta√ß√£o profissional (READMEs).